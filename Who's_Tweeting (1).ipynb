{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEqcWx4CoTrv"
   },
   "source": [
    "# Who's Tweeting? Trump vs Trudeau \n",
    "## is a project I've seen on Datacamp. It asks you to classify a given tweet of either Donald Trump or Justin Trudeau.\n",
    "The dataset consists of three columns, ID, Tweet itself and the authors (being either Donald Trump or Justin Trudeau). I have used support vector classifier and logistic regressor in this code, and also compared two word vectorizers; count vectorizer and TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NbyyZ0NEpAFf"
   },
   "source": [
    "**Importing the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ly7WHli6pD7q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4MhV2qjpPQ1"
   },
   "source": [
    "**Importing the data, and I've also removed the label row that was given in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4YW2d6TpY-E"
   },
   "outputs": [],
   "source": [
    "tweetsdf = pd.read_csv('/Users/Merveilleux/Downloads/tweets.csv', sep=',', names=('ID', 'Author', 'tweet'))\n",
    "tweetsdf=tweetsdf.iloc[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3utUuJYXpeE0"
   },
   "source": [
    "**We will predict the author from the tweet column, splitting the data as training and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-WXV8KQ0pnc2"
   },
   "outputs": [],
   "source": [
    "y=tweetsdf['Author']\n",
    "x=tweetsdf['tweet']\n",
    "x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.33, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NB9eLIKmpptc"
   },
   "source": [
    "**TF-IDF vectorizer, vectorizes the words by dividing the frequency of that specific word by how many times that word appears in how many documents, it yields a matrix with values between 0 and 1 so it gives better precision than the count vectorizer**\n",
    "It removes English stopwords, and n-gram determines the number of words taken in a phrase, and max and min df values get rid of words either used too much or too rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3i0sPOmqfDG"
   },
   "outputs": [],
   "source": [
    "tvec= TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_df=0.9, min_df=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOja5y05qk7H"
   },
   "source": [
    "Splitting the data for the comparison of vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsddOPnNqj1_"
   },
   "outputs": [],
   "source": [
    "t_train=tvec.fit_transform(x_train)\n",
    "t_test=tvec.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LA0Yr3fAqqOO"
   },
   "source": [
    "**Count vectorizer basically counts the words that appear and returns a matrix with columns being the words and rows being tweets.** The elements of matrix are integers. Applying the same procedure with TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQOevIxTq6FF"
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words=\"english\",ngram_range=(1,2), max_df=0.9, min_df=0.05)\n",
    "c_train=cvec.fit_transform(x_train)\n",
    "c_test=cvec.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpXybZ7nq82f"
   },
   "source": [
    "**Classification with SVC with RBF kernel on the TF-IDF data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5USIkYJdrKzD"
   },
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(t_train, y_train)\n",
    "t_predsvc = svclassifier.predict(t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wM6ItAUMrOW1"
   },
   "source": [
    "**Classification with SVC with RBF kernel on Count Vectorizer data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9lrsLYPirNBf"
   },
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(c_train, y_train)\n",
    "c_predsvc = svclassifier.predict(c_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvXZi18GrXKe"
   },
   "source": [
    "**Calculation of accuracies of both vectorizers with SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8CdNFrqrd9L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70  7]\n",
      " [16 39]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Donald J. Trump       0.81      0.91      0.86        77\n",
      " Justin Trudeau       0.85      0.71      0.77        55\n",
      "\n",
      "    avg / total       0.83      0.83      0.82       132\n",
      "\n",
      "[[64 13]\n",
      " [ 8 47]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Donald J. Trump       0.89      0.83      0.86        77\n",
      " Justin Trudeau       0.78      0.85      0.82        55\n",
      "\n",
      "    avg / total       0.84      0.84      0.84       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countsvcacc = accuracy_score(c_predsvc,y_test)\n",
    "print(confusion_matrix(y_test,c_predsvc))\n",
    "print(classification_report(y_test,c_predsvc))\n",
    "\n",
    "tfidfsvmacc = accuracy_score(t_predsvc,y_test)\n",
    "print(confusion_matrix(y_test,t_predsvc))\n",
    "print(classification_report(y_test,t_predsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPMuEBhPrjBs"
   },
   "source": [
    "**Classification with logistic regressor on the TF-IDF data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRJYzdswsVMT"
   },
   "outputs": [],
   "source": [
    "logclassifier=LogisticRegression(random_state=0, solver='lbfgs') \n",
    "logclassifier.fit(t_train, y_train) \n",
    "t_predlog = logclassifier.predict(t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bFfuP_nr17Z"
   },
   "source": [
    "**Classification with logistic regressor on the Count Vectorizer data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKqDPdDLr6Hw"
   },
   "outputs": [],
   "source": [
    "logclassifier=LogisticRegression(random_state=0, solver='lbfgs')\n",
    "logclassifier.fit(c_train, y_train)\n",
    "c_predlog = logclassifier.predict(c_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJwb5HOwsBaT"
   },
   "source": [
    "**Calculation of accuracies of both vectorizers with Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_g-aMMy3sIZ5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65 12]\n",
      " [12 43]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Donald J. Trump       0.84      0.84      0.84        77\n",
      " Justin Trudeau       0.78      0.78      0.78        55\n",
      "\n",
      "    avg / total       0.82      0.82      0.82       132\n",
      "\n",
      "[[64 13]\n",
      " [10 45]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Donald J. Trump       0.86      0.83      0.85        77\n",
      " Justin Trudeau       0.78      0.82      0.80        55\n",
      "\n",
      "    avg / total       0.83      0.83      0.83       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countlogacc = accuracy_score(c_predlog,y_test)\n",
    "print(confusion_matrix(y_test,c_predlog))\n",
    "print(classification_report(y_test,c_predlog))\n",
    "\n",
    "countlogacc = accuracy_score(t_predlog,y_test)\n",
    "print(confusion_matrix(y_test,t_predlog))\n",
    "print(classification_report(y_test,t_predlog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFsbvMcGsZLU"
   },
   "source": [
    "**Confusion matrices for both vectorizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QB_NtfmEsg4G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64 10]\n",
      " [13 45]]\n",
      "[[65 12]\n",
      " [12 43]]\n",
      "[[64  8]\n",
      " [13 47]]\n",
      "[[70 16]\n",
      " [ 7 39]]\n"
     ]
    }
   ],
   "source": [
    "tlog_confmatrix = confusion_matrix(t_predlog,y_test)\n",
    "clog_confmatrix = confusion_matrix(c_predlog,y_test)\n",
    "\n",
    "tsvc_confmatrix = confusion_matrix(t_predsvc,y_test)\n",
    "csvc_confmatrix = confusion_matrix(c_predsvc,y_test)\n",
    "print(tlog_confmatrix)\n",
    "print(clog_confmatrix)\n",
    "print(tsvc_confmatrix)\n",
    "print(csvc_confmatrix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Who's Tweeting? Trump v Trudeau.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
