{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Who's Tweeting? Trump v Trudeau.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merveenoyan/whostweeting/blob/master/Who's_Tweeting%3F_Trump_v_Trudeau.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEqcWx4CoTrv",
        "colab_type": "text"
      },
      "source": [
        "# Who's Tweeting? Trump vs Trudeau \n",
        "## is a project I've seen on Datacamp. It asks you to classify a given tweet of either Donald Trump or Justin Trudeau.\n",
        "The dataset consists of three columns, ID, Tweet itself and the authors (being either Donald Trump or Justin Trudeau). I have used support vector classifier and logistic regressor in this code, and also compared two word vectorizers; count vectorizer and TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbyyZ0NEpAFf",
        "colab_type": "text"
      },
      "source": [
        "**Importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly7WHli6pD7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4MhV2qjpPQ1",
        "colab_type": "text"
      },
      "source": [
        "**Importing the data, and I've also removed the label row that was given in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4YW2d6TpY-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweetsdf = pd.read_table('/Users/Merveilleux/Desktop/tweets.txt', sep=',', names=('ID', 'Author', 'tweet'))\n",
        "tweetsdf=tweetsdf.iloc[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3utUuJYXpeE0",
        "colab_type": "text"
      },
      "source": [
        "**We will predict the author from the tweet column, splitting the data as training and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WXV8KQ0pnc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=tweetsdf['Author']\n",
        "x=tweetsdf['tweet']\n",
        "x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.33, random_state=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB9eLIKmpptc",
        "colab_type": "text"
      },
      "source": [
        "**TF-IDF vectorizer, vectorizes the words by dividing the frequency of that specific word by how many times that word appears in how many documents, it yields a matrix with values between 0 and 1 so it gives better precision than the count vectorizer**\n",
        "It removes English stopwords, and n-gram determines the number of words taken in a phrase, and max and min df values get rid of words either used too much or too rare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3i0sPOmqfDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tvec= TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_df=0.9, min_df=0.05)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOja5y05qk7H",
        "colab_type": "text"
      },
      "source": [
        "Splitting the data for the comparison of vectorizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsddOPnNqj1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_train=tvec.fit_transform(x_train)\n",
        "t_test=tvec.fit_transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA0Yr3fAqqOO",
        "colab_type": "text"
      },
      "source": [
        "**Count vectorizer basically counts the words that appear and returns a matrix with columns being the words and rows being tweets.** The elements of matrix are integers. Applying the same procedure with TF-IDF. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQOevIxTq6FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvec = CountVectorizer(stop_words=\"english\",ngram_range=(1,2), max_df=0.9, min_df=0.05)\n",
        "c_train=cvec.fit_transform(x_train)\n",
        "c_test=cvec.fit_transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpXybZ7nq82f",
        "colab_type": "text"
      },
      "source": [
        "**Classification with SVC with RBF kernel on the TF-IDF data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5USIkYJdrKzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(t_train, y_train)\n",
        "t_predsvc = svclassifier.predict(t_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM6ItAUMrOW1",
        "colab_type": "text"
      },
      "source": [
        "**Classification with SVC with RBF kernel on Count Vectorizer data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lrsLYPirNBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(c_train, y_train)\n",
        "c_predsvc = svclassifier.predict(c_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvXZi18GrXKe",
        "colab_type": "text"
      },
      "source": [
        "**Calculation of accuracies of both vectorizers with SVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8CdNFrqrd9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "countsvcacc = accuracy_score(c_predsvc,y_test)\n",
        "print(confusion_matrix(y_test,c_predsvc))\n",
        "print(classification_report(y_test,c_predsvc))\n",
        "\n",
        "tfidfsvmacc = accuracy_score(t_predsvc,y_test)\n",
        "print(confusion_matrix(y_test,t_predsvc))\n",
        "print(classification_report(y_test,t_predsvc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPMuEBhPrjBs",
        "colab_type": "text"
      },
      "source": [
        "**Classification with logistic regressor on the TF-IDF data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRJYzdswsVMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logclassifier=LogisticRegression(random_state=0, solver='lbfgs') logclassifier.fit(t_train, y_train) t_predlog = logclassifier.predict("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bFfuP_nr17Z",
        "colab_type": "text"
      },
      "source": [
        "**Classification with logistic regressor on the Count Vectorizer data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKqDPdDLr6Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logclassifier=LogisticRegression(random_state=0, solver='lbfgs')\n",
        "logclassifier.fit(c_train, y_train)\n",
        "c_predlog = logclassifier.predict(c_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJwb5HOwsBaT",
        "colab_type": "text"
      },
      "source": [
        "**Calculation of accuracies of both vectorizers with Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g-aMMy3sIZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "countlogacc = accuracy_score(c_predlog,y_test)\n",
        "print(confusion_matrix(y_test,c_predlog))\n",
        "print(classification_report(y_test,c_predlog))\n",
        "\n",
        "countlogacc = accuracy_score(t_predlog,y_test)\n",
        "print(confusion_matrix(y_test,t_predlog))\n",
        "print(classification_report(y_test,t_predlog))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFsbvMcGsZLU",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrices for both vectorizers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB_NtfmEsg4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tlog_confmatrix = confusion_matrix(t_predlog,y_test)\n",
        "clog_confmatrix = confusion_matrix(c_predlog,y_test)\n",
        "\n",
        "tsvc_confmatrix = confusion_matrix(t_predsvc,y_test)\n",
        "csvc_confmatrix = confusion_matrix(c_predsvc,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}