{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Who's Tweeting? Trump v Trudeau.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merveenoyan/whostweeting/blob/master/Who's_Tweeting%3F_Trump_v_Trudeau.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEqcWx4CoTrv",
        "colab_type": "text"
      },
      "source": [
        "# Who's Tweeting? Trump vs Trudeau \n",
        "## is a project I've seen on Datacamp. It asks you to classify a given tweet of either Donald Trump or Justin Trudeau.\n",
        "The dataset consists of three columns, ID, Tweet itself and the authors (being either Donald Trump or Justin Trudeau). I have used support vector classifier and logistic regressor in this code, and also compared two word vectorizers; count vectorizer and TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbyyZ0NEpAFf",
        "colab_type": "text"
      },
      "source": [
        "**Importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly7WHli6pD7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4MhV2qjpPQ1",
        "colab_type": "text"
      },
      "source": [
        "**Importing the data, and I've also removed the label row that was given in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4YW2d6TpY-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "05159495-068d-4d8e-93f7-5614b3e75070"
      },
      "source": [
        "tweetsdf = pd.read_table('/content/tweets.csv', sep=',', names=('ID', 'Author', 'tweet'))\n",
        "tweetsdf=tweetsdf.iloc[1:]\n",
        "tweetsdf.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Author</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Donald J. Trump</td>\n",
              "      <td>I will be making a major statement from the @W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Donald J. Trump</td>\n",
              "      <td>Just arrived at #ASEAN50 in the Philippines fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Donald J. Trump</td>\n",
              "      <td>After my tour of Asia, all Countries dealing w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Donald J. Trump</td>\n",
              "      <td>Great to see @RandPaul looking well and back o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Donald J. Trump</td>\n",
              "      <td>Excited to be heading home to see the House pa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ID           Author                                              tweet\n",
              "1  1  Donald J. Trump  I will be making a major statement from the @W...\n",
              "2  2  Donald J. Trump  Just arrived at #ASEAN50 in the Philippines fo...\n",
              "3  3  Donald J. Trump  After my tour of Asia, all Countries dealing w...\n",
              "4  4  Donald J. Trump  Great to see @RandPaul looking well and back o...\n",
              "5  5  Donald J. Trump  Excited to be heading home to see the House pa..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3utUuJYXpeE0",
        "colab_type": "text"
      },
      "source": [
        "**We will predict the author from the tweet column, splitting the data as training and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WXV8KQ0pnc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=tweetsdf['Author']\n",
        "x=tweetsdf['tweet']\n",
        "x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.33, random_state=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB9eLIKmpptc",
        "colab_type": "text"
      },
      "source": [
        "**TF-IDF vectorizer, vectorizes the words by dividing the frequency of that specific word by how many times that word appears in how many documents, it yields a matrix with values between 0 and 1 so it gives better precision than the count vectorizer**\n",
        "It removes English stopwords, and n-gram determines the number of words taken in a phrase, and max and min df values get rid of words either used too much or too rare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3i0sPOmqfDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tvec= TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_df=0.9, min_df=0.05)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOja5y05qk7H",
        "colab_type": "text"
      },
      "source": [
        "Splitting the data for the comparison of vectorizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsddOPnNqj1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_train=tvec.fit_transform(x_train)\n",
        "t_test=tvec.fit_transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA0Yr3fAqqOO",
        "colab_type": "text"
      },
      "source": [
        "**Count vectorizer basically counts the words that appear and returns a matrix with columns being the words and rows being tweets.** The elements of matrix are integers. Applying the same procedure with TF-IDF. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQOevIxTq6FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvec = CountVectorizer(stop_words=\"english\",ngram_range=(1,2), max_df=0.9, min_df=0.05)\n",
        "c_train=cvec.fit_transform(x_train)\n",
        "c_test=cvec.fit_transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpXybZ7nq82f",
        "colab_type": "text"
      },
      "source": [
        "**Classification with SVC with RBF kernel on the TF-IDF data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5USIkYJdrKzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f689e9dd-1674-4249-8c47-ffa549cdd6f3"
      },
      "source": [
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(t_train, y_train)\n",
        "t_predsvc = svclassifier.predict(t_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM6ItAUMrOW1",
        "colab_type": "text"
      },
      "source": [
        "**Classification with SVC with RBF kernel on Count Vectorizer data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lrsLYPirNBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dfdc4da7-4873-47fa-c274-763e7d8a2bc3"
      },
      "source": [
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(c_train, y_train)\n",
        "c_predsvc = svclassifier.predict(c_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvXZi18GrXKe",
        "colab_type": "text"
      },
      "source": [
        "**Calculation of accuracies of both vectorizers with SVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8CdNFrqrd9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0511f50b-cd0b-4d58-d443-4e9b543593b3"
      },
      "source": [
        "countsvcacc = accuracy_score(c_predsvc,y_test)\n",
        "print(confusion_matrix(y_test,c_predsvc))\n",
        "print(classification_report(y_test,c_predsvc))\n",
        "\n",
        "tfidfsvmacc = accuracy_score(t_predsvc,y_test)\n",
        "print(confusion_matrix(y_test,t_predsvc))\n",
        "print(classification_report(y_test,t_predsvc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[70  7]\n",
            " [16 39]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Donald J. Trump       0.81      0.91      0.86        77\n",
            " Justin Trudeau       0.85      0.71      0.77        55\n",
            "\n",
            "       accuracy                           0.83       132\n",
            "      macro avg       0.83      0.81      0.82       132\n",
            "   weighted avg       0.83      0.83      0.82       132\n",
            "\n",
            "[[64 13]\n",
            " [ 8 47]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Donald J. Trump       0.89      0.83      0.86        77\n",
            " Justin Trudeau       0.78      0.85      0.82        55\n",
            "\n",
            "       accuracy                           0.84       132\n",
            "      macro avg       0.84      0.84      0.84       132\n",
            "   weighted avg       0.84      0.84      0.84       132\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPMuEBhPrjBs",
        "colab_type": "text"
      },
      "source": [
        "**Classification with logistic regressor on the TF-IDF data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRJYzdswsVMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logclassifier=LogisticRegression(random_state=0, solver='lbfgs') \n",
        "logclassifier.fit(t_train, y_train) \n",
        "t_predlog = logclassifier.predict(t_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bFfuP_nr17Z",
        "colab_type": "text"
      },
      "source": [
        "**Classification with logistic regressor on the Count Vectorizer data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKqDPdDLr6Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logclassifier=LogisticRegression(random_state=0, solver='lbfgs')\n",
        "logclassifier.fit(c_train, y_train)\n",
        "c_predlog = logclassifier.predict(c_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJwb5HOwsBaT",
        "colab_type": "text"
      },
      "source": [
        "**Calculation of accuracies of both vectorizers with Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g-aMMy3sIZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "945b6a2a-f4cd-4da2-c52d-380e0188a146"
      },
      "source": [
        "countlogacc = accuracy_score(c_predlog,y_test)\n",
        "print(confusion_matrix(y_test,c_predlog))\n",
        "print(classification_report(y_test,c_predlog))\n",
        "\n",
        "countlogacc = accuracy_score(t_predlog,y_test)\n",
        "print(confusion_matrix(y_test,t_predlog))\n",
        "print(classification_report(y_test,t_predlog))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[65 12]\n",
            " [12 43]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Donald J. Trump       0.84      0.84      0.84        77\n",
            " Justin Trudeau       0.78      0.78      0.78        55\n",
            "\n",
            "       accuracy                           0.82       132\n",
            "      macro avg       0.81      0.81      0.81       132\n",
            "   weighted avg       0.82      0.82      0.82       132\n",
            "\n",
            "[[64 13]\n",
            " [10 45]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Donald J. Trump       0.86      0.83      0.85        77\n",
            " Justin Trudeau       0.78      0.82      0.80        55\n",
            "\n",
            "       accuracy                           0.83       132\n",
            "      macro avg       0.82      0.82      0.82       132\n",
            "   weighted avg       0.83      0.83      0.83       132\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFsbvMcGsZLU",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrices for both vectorizers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB_NtfmEsg4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "217ae760-1694-4f59-a062-6f7cadafcef2"
      },
      "source": [
        "tlog_confmatrix = confusion_matrix(t_predlog,y_test)\n",
        "clog_confmatrix = confusion_matrix(c_predlog,y_test)\n",
        "\n",
        "tsvc_confmatrix = confusion_matrix(t_predsvc,y_test)\n",
        "csvc_confmatrix = confusion_matrix(c_predsvc,y_test)\n",
        "\n",
        "print(tlog_confmatrix)\n",
        "print(clog_confmatrix)\n",
        "print(csvc_confmatrix)\n",
        "print(tsvc_confmatrix)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[64 10]\n",
            " [13 45]]\n",
            "[[65 12]\n",
            " [12 43]]\n",
            "[[70 16]\n",
            " [ 7 39]]\n",
            "[[64  8]\n",
            " [13 47]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}